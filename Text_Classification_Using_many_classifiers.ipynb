{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Classification Using many classifiers.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_FtbI_Y2ByV"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WY2bsqyu2Hm2"
      },
      "source": [
        " We will be using a dataset called \"Economic news article tone and relevance\" from Figure-Eight (https://www.figure-eight.com/data-for-everyone/) which consists of approximately 8000 news articles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkWraXmO2J6I"
      },
      "source": [
        "# reading dataset\n",
        "\n",
        "our_data = pd.read_csv('/content/Full-Economic-News-DFE-839861.csv',encoding = \"ISO-8859-1\" )"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OHhAHT22QLj",
        "outputId": "2ff6ff63-19ac-404a-927d-b00016388343",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        }
      },
      "source": [
        "our_data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_unit_id</th>\n",
              "      <th>_golden</th>\n",
              "      <th>_unit_state</th>\n",
              "      <th>_trusted_judgments</th>\n",
              "      <th>_last_judgment_at</th>\n",
              "      <th>positivity</th>\n",
              "      <th>positivity:confidence</th>\n",
              "      <th>relevance</th>\n",
              "      <th>relevance:confidence</th>\n",
              "      <th>articleid</th>\n",
              "      <th>date</th>\n",
              "      <th>headline</th>\n",
              "      <th>positivity_gold</th>\n",
              "      <th>relevance_gold</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842613455</td>\n",
              "      <td>False</td>\n",
              "      <td>finalized</td>\n",
              "      <td>3</td>\n",
              "      <td>12/5/15 17:48</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.6400</td>\n",
              "      <td>yes</td>\n",
              "      <td>0.640</td>\n",
              "      <td>wsj_398217788</td>\n",
              "      <td>8/14/91</td>\n",
              "      <td>Yields on CDs Fell in the Latest Week</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NEW YORK -- Yields on most certificates of dep...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842613456</td>\n",
              "      <td>False</td>\n",
              "      <td>finalized</td>\n",
              "      <td>3</td>\n",
              "      <td>12/5/15 16:54</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>no</td>\n",
              "      <td>1.000</td>\n",
              "      <td>wsj_399019502</td>\n",
              "      <td>8/21/07</td>\n",
              "      <td>The Morning Brief: White House Seeks to Limit ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The Wall Street Journal Online&lt;/br&gt;&lt;/br&gt;The Mo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>842613457</td>\n",
              "      <td>False</td>\n",
              "      <td>finalized</td>\n",
              "      <td>3</td>\n",
              "      <td>12/5/15 1:59</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>no</td>\n",
              "      <td>1.000</td>\n",
              "      <td>wsj_398284048</td>\n",
              "      <td>11/14/91</td>\n",
              "      <td>Banking Bill Negotiators Set Compromise --- Pl...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>WASHINGTON -- In an effort to achieve banking ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>842613458</td>\n",
              "      <td>False</td>\n",
              "      <td>finalized</td>\n",
              "      <td>3</td>\n",
              "      <td>12/5/15 2:19</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>no</td>\n",
              "      <td>0.675</td>\n",
              "      <td>wsj_397959018</td>\n",
              "      <td>6/16/86</td>\n",
              "      <td>Manager's Journal: Sniffing Out Drug Abusers I...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The statistics on the enormous costs of employ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>842613459</td>\n",
              "      <td>False</td>\n",
              "      <td>finalized</td>\n",
              "      <td>3</td>\n",
              "      <td>12/5/15 17:48</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.3257</td>\n",
              "      <td>yes</td>\n",
              "      <td>0.640</td>\n",
              "      <td>wsj_398838054</td>\n",
              "      <td>10/4/02</td>\n",
              "      <td>Currency Trading: Dollar Remains in Tight Rang...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NEW YORK -- Indecision marked the dollar's ton...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    _unit_id  ...                                               text\n",
              "0  842613455  ...  NEW YORK -- Yields on most certificates of dep...\n",
              "1  842613456  ...  The Wall Street Journal Online</br></br>The Mo...\n",
              "2  842613457  ...  WASHINGTON -- In an effort to achieve banking ...\n",
              "3  842613458  ...  The statistics on the enormous costs of employ...\n",
              "4  842613459  ...  NEW YORK -- Indecision marked the dollar's ton...\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFsRXX5u4P2c"
      },
      "source": [
        "# convert label to a numerical variable\n",
        "our_data = our_data[our_data.relevance != \"not sure\"]\n",
        "our_data.shape\n",
        "our_data['relevance'] = our_data.relevance.map({'yes':1, 'no':0}) #relevant is 1, not-relevant is 0. \n",
        "our_data = our_data[[\"text\",\"relevance\"]] #Let us take only the two columns we need."
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKv5LEoi44Pb"
      },
      "source": [
        "#import feature extraction methods from sklearn\n",
        "import string\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction import stop_words\n",
        "stopwords = stop_words.ENGLISH_STOP_WORDS\n",
        "\n",
        "def clean(doc): #doc is a string of text\n",
        "    doc = doc.replace(\"</br>\", \" \") # a lot of <br/> tags.\n",
        "    doc = \"\".join([char for char in doc if char not in string.punctuation and not char.isdigit()])\n",
        "    doc = \" \".join([token for token in doc.split() if token not in stopwords])\n",
        "    #remove punctuation and numbers\n",
        "    return doc\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tObY8xqz5jxH",
        "outputId": "27c34f03-6635-4cc1-a933-4ad993d32e22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(clean(\"the man\"))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "man\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-Jf_Yfa5lR6"
      },
      "source": [
        "# PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPhIlLo05oFt",
        "outputId": "1a896370-43dc-49bc-b4b8-baf91a62793e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import sklearn\n",
        "#from sklearn.cross_validation import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Step 1: train-test split\n",
        "X = our_data.text #the column text contains textual data to extract features from\n",
        "y = our_data.relevance #this is the column we are learning to predict. \n",
        "print(X.shape, y.shape)\n",
        "# split X and y into training and testing sets. By default, it splits 75% training and 25% test\n",
        "#random_state=1 for reproducibility\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7991,) (7991,)\n",
            "(5993,) (5993,)\n",
            "(1998,) (1998,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrXC3Jo-6dnk",
        "outputId": "b77661a8-2aea-443a-c470-e75458a50091",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# vectorizer\n",
        "vect = CountVectorizer(preprocessor=clean) #instantiate a vectoriezer\n",
        "X_train_dtm = vect.fit_transform(X_train)#use it to extract features from training data\n",
        "#transform testing data (using training data's features)\n",
        "X_test_dtm = vect.transform(X_test)\n",
        "print(X_train_dtm.shape, X_test_dtm.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5993, 49753) (1998, 49753)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRUvMePW6vVu"
      },
      "source": [
        "#import classifiers from sklearn\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "#import different metrics to evaluate the classifiers\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.metrics import confusion_matrix \n",
        "\n",
        "import sklearn.metrics as metrics"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx_34lDZ64Wh"
      },
      "source": [
        "nb = MultinomialNB() #instantiate a Multinomial Naive Bayes classifier\n",
        "nb.fit(X_train_dtm, y_train)#train the model\n",
        "y_pred_class = nb.predict(X_test_dtm)#make class predictions for test data"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxqFX6_b7S34",
        "outputId": "a6346484-53e8-40f4-ca3c-4885fad3c911",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Print accuracy:\n",
        "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred_class))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7822822822822822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pK74jKOl7jss"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2dTvWGH8YKS"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlnbuRND8bPW",
        "outputId": "4b6d7df1-d8a2-4887-f15f-c3930eb70fea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression #import\n",
        "\n",
        "logreg = LogisticRegression(class_weight=\"balanced\") #instantiate a logistic regression model\n",
        "logreg.fit(X_train_dtm, y_train) #fit the model with training data\n",
        "\n",
        "#Make predictions on test data\n",
        "y_pred_class = logreg.predict(X_test_dtm)\n",
        "\n",
        "#calculate evaluation measures:\n",
        "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred_class))\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7682682682682682\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBWN4WSDAB1x"
      },
      "source": [
        "# Using Pretrained Word Embeddings from Google News"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EQwqKgC8shO",
        "outputId": "8847ac34-2b11-41b2-cad1-ccb92e5093dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "model = api.load(\"word2vec-google-news-300\")  # download the model and return as object ready for use\n",
        "word_vectors = model.wv #load the vectors from the model"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS9Zg8xj_2La",
        "outputId": "c2b17dd7-5849-4397-a1d2-298cd09b9e3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "word_vectors"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x7f5ae49bc278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i233jBXMBgWh",
        "outputId": "17bef0a0-215d-4a07-de61-949e44ac737b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "# look up top 6 words similar to 'polite'\n",
        "w1 = [\"polite\"]\n",
        "model.wv.most_similar (positive=w1,topn=6)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('courteous', 0.7520973682403564),\n",
              " ('everybody_Pendergrast', 0.7189083099365234),\n",
              " ('respectful', 0.6748367547988892),\n",
              " ('mannerly', 0.6553859710693359),\n",
              " ('gracious', 0.6316325664520264),\n",
              " ('considerate', 0.6307362914085388)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY5zLtrbCPtN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}